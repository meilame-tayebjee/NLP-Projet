{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "import numpy as np\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return clf_metrics.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Breton Cyrille menuisier 25 Garçon française</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferazzi Auguste vitrier 30 Garçon Piémontaise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machol Pierre vitrier 24 Garçon Piémontaise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desbois Alexandre prop re 48 Homme marié franç...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vignat Zélie prop re sa fe 30 française</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>Chameton-Dideron Marie chef 1869 idem Pailharès</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25076</th>\n",
       "      <td>Ode Marie ouv chaus res chef Cara 1863 idem St...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25077</th>\n",
       "      <td>Berni Nello manoeuvre chef Baretto 1886 italie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25078</th>\n",
       "      <td>Berni-Laureti Annunziata épouse 1887 idem idem</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25079</th>\n",
       "      <td>Berni Primo fils 1914 idem idem</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25080 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0           Breton Cyrille menuisier 25 Garçon française      0\n",
       "1          Ferazzi Auguste vitrier 30 Garçon Piémontaise      1\n",
       "2            Machol Pierre vitrier 24 Garçon Piémontaise      1\n",
       "3      Desbois Alexandre prop re 48 Homme marié franç...      1\n",
       "4                Vignat Zélie prop re sa fe 30 française      0\n",
       "...                                                  ...    ...\n",
       "25075    Chameton-Dideron Marie chef 1869 idem Pailharès      1\n",
       "25076  Ode Marie ouv chaus res chef Cara 1863 idem St...      1\n",
       "25077  Berni Nello manoeuvre chef Baretto 1886 italie...      1\n",
       "25078     Berni-Laureti Annunziata épouse 1887 idem idem      0\n",
       "25079                    Berni Primo fils 1914 idem idem      0\n",
       "\n",
       "[25080 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('entities.csv', sep=',')\n",
    "df.rename(columns={'chef':'label', 'texte':'text'}, inplace=True)\n",
    "df.label = df.label.astype('int')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, batched = True):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Rabier néant femme 1859 française', 'label': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8a797732224ba69f8c68cdc1bedb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15a30bbc0b348ab99e569494ee9bf0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6a0eefde524559ace58a44d882cb4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_testvalid = dataset.train_test_split(0.2, seed=42)\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(0.5)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']})\n",
    "\n",
    "dataset = train_test_valid_dataset\n",
    "tokenized_text = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding = 'longest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    fp16 = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6270' max='6270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6270/6270 06:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.415600</td>\n",
       "      <td>0.228706</td>\n",
       "      <td>0.917065</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.870466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.200801</td>\n",
       "      <td>0.926635</td>\n",
       "      <td>0.849673</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.898100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.221100</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.931021</td>\n",
       "      <td>0.859464</td>\n",
       "      <td>0.811350</td>\n",
       "      <td>0.913644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.187840</td>\n",
       "      <td>0.933413</td>\n",
       "      <td>0.864558</td>\n",
       "      <td>0.814985</td>\n",
       "      <td>0.920553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.194900</td>\n",
       "      <td>0.183977</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.867043</td>\n",
       "      <td>0.812689</td>\n",
       "      <td>0.929188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.182843</td>\n",
       "      <td>0.933812</td>\n",
       "      <td>0.866559</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.930915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.180792</td>\n",
       "      <td>0.933413</td>\n",
       "      <td>0.866932</td>\n",
       "      <td>0.804734</td>\n",
       "      <td>0.939551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.181291</td>\n",
       "      <td>0.935008</td>\n",
       "      <td>0.868654</td>\n",
       "      <td>0.814199</td>\n",
       "      <td>0.930915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.191900</td>\n",
       "      <td>0.180251</td>\n",
       "      <td>0.934609</td>\n",
       "      <td>0.868800</td>\n",
       "      <td>0.809240</td>\n",
       "      <td>0.937824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.180036</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.867682</td>\n",
       "      <td>0.809880</td>\n",
       "      <td>0.934370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6270, training_loss=0.21743381019604452, metrics={'train_runtime': 369.9584, 'train_samples_per_second': 542.331, 'train_steps_per_second': 16.948, 'total_flos': 1194052852272768.0, 'train_loss': 0.21743381019604452, 'epoch': 10.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    fp16 = True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_text[\"train\"],\n",
    "    eval_dataset=tokenized_text[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07177033492822966\n"
     ]
    }
   ],
   "source": [
    "#Evaluate on test set \n",
    "predictions = trainer.predict(tokenized_text[\"test\"])\n",
    "print(np.mean(predictions.predictions.argmax(axis=1) != predictions.label_ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1830,  147],\n",
       "       [  33,  498]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions.label_ids, predictions.predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e981cf16a104c2db35d71893da5fd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66920bddc2f94e679ffb7782f49e262c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5867007518324690bdc2dd37fdf74d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6270' max='6270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6270/6270 04:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.393400</td>\n",
       "      <td>0.224687</td>\n",
       "      <td>0.913078</td>\n",
       "      <td>0.813675</td>\n",
       "      <td>0.806780</td>\n",
       "      <td>0.820690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.232600</td>\n",
       "      <td>0.197551</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.847512</td>\n",
       "      <td>0.792793</td>\n",
       "      <td>0.910345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>0.192087</td>\n",
       "      <td>0.927831</td>\n",
       "      <td>0.853441</td>\n",
       "      <td>0.804580</td>\n",
       "      <td>0.908621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.186590</td>\n",
       "      <td>0.933812</td>\n",
       "      <td>0.866774</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.197300</td>\n",
       "      <td>0.187413</td>\n",
       "      <td>0.930223</td>\n",
       "      <td>0.858300</td>\n",
       "      <td>0.809160</td>\n",
       "      <td>0.913793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>0.182363</td>\n",
       "      <td>0.933812</td>\n",
       "      <td>0.866987</td>\n",
       "      <td>0.809880</td>\n",
       "      <td>0.932759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.193900</td>\n",
       "      <td>0.182802</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.181591</td>\n",
       "      <td>0.933812</td>\n",
       "      <td>0.867200</td>\n",
       "      <td>0.808955</td>\n",
       "      <td>0.934483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.181384</td>\n",
       "      <td>0.933812</td>\n",
       "      <td>0.866987</td>\n",
       "      <td>0.809880</td>\n",
       "      <td>0.932759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.181484</td>\n",
       "      <td>0.933812</td>\n",
       "      <td>0.866987</td>\n",
       "      <td>0.809880</td>\n",
       "      <td>0.932759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2547d2546d5b4a5bbb701038a6d2f8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce39b15867594f44805b629268867596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ccb99d475f429e8ab7095170094f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6270' max='6270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6270/6270 04:57, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.246059</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.773038</td>\n",
       "      <td>0.826642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.228200</td>\n",
       "      <td>0.230042</td>\n",
       "      <td>0.916268</td>\n",
       "      <td>0.815141</td>\n",
       "      <td>0.787415</td>\n",
       "      <td>0.844891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.211400</td>\n",
       "      <td>0.221751</td>\n",
       "      <td>0.921850</td>\n",
       "      <td>0.826549</td>\n",
       "      <td>0.802405</td>\n",
       "      <td>0.852190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.195600</td>\n",
       "      <td>0.213415</td>\n",
       "      <td>0.927033</td>\n",
       "      <td>0.840731</td>\n",
       "      <td>0.803661</td>\n",
       "      <td>0.881387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.193300</td>\n",
       "      <td>0.207909</td>\n",
       "      <td>0.928628</td>\n",
       "      <td>0.844753</td>\n",
       "      <td>0.804959</td>\n",
       "      <td>0.888686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.212107</td>\n",
       "      <td>0.927432</td>\n",
       "      <td>0.841187</td>\n",
       "      <td>0.806020</td>\n",
       "      <td>0.879562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.209662</td>\n",
       "      <td>0.928230</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.805648</td>\n",
       "      <td>0.885036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.208596</td>\n",
       "      <td>0.927831</td>\n",
       "      <td>0.842472</td>\n",
       "      <td>0.805324</td>\n",
       "      <td>0.883212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.207074</td>\n",
       "      <td>0.928628</td>\n",
       "      <td>0.844483</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.886861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.207060</td>\n",
       "      <td>0.928230</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.805648</td>\n",
       "      <td>0.885036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e7f9ec55eb4af3955ed0ff6a0fb2fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b86f354d2242e7bd0a26aa7c9f1bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47874d29d17456ea1bd1083dbb6ba29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6270' max='6270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6270/6270 04:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.383100</td>\n",
       "      <td>0.243398</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.792746</td>\n",
       "      <td>0.758678</td>\n",
       "      <td>0.830018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.215203</td>\n",
       "      <td>0.919856</td>\n",
       "      <td>0.826275</td>\n",
       "      <td>0.791391</td>\n",
       "      <td>0.864376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>0.203493</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.836207</td>\n",
       "      <td>0.799012</td>\n",
       "      <td>0.877034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.197800</td>\n",
       "      <td>0.196594</td>\n",
       "      <td>0.925837</td>\n",
       "      <td>0.840753</td>\n",
       "      <td>0.798374</td>\n",
       "      <td>0.887884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.196250</td>\n",
       "      <td>0.926635</td>\n",
       "      <td>0.842466</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.889693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>0.189247</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.850594</td>\n",
       "      <td>0.801600</td>\n",
       "      <td>0.905967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>0.187894</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.850847</td>\n",
       "      <td>0.800638</td>\n",
       "      <td>0.907776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.187772</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.855207</td>\n",
       "      <td>0.804140</td>\n",
       "      <td>0.913201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.188695</td>\n",
       "      <td>0.930223</td>\n",
       "      <td>0.851317</td>\n",
       "      <td>0.802885</td>\n",
       "      <td>0.905967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.187734</td>\n",
       "      <td>0.930622</td>\n",
       "      <td>0.852542</td>\n",
       "      <td>0.802233</td>\n",
       "      <td>0.909584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238387858e884b42a2a1527e9f46bd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7f5ac6717049ea88e2d8768e6f21e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dab773646734ffab6b5fa3ba59d0c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6270' max='6270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6270/6270 04:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.242089</td>\n",
       "      <td>0.905502</td>\n",
       "      <td>0.798982</td>\n",
       "      <td>0.757235</td>\n",
       "      <td>0.845601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.233700</td>\n",
       "      <td>0.204700</td>\n",
       "      <td>0.925837</td>\n",
       "      <td>0.842373</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.892280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.204400</td>\n",
       "      <td>0.192277</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.856664</td>\n",
       "      <td>0.803459</td>\n",
       "      <td>0.917415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.198900</td>\n",
       "      <td>0.189110</td>\n",
       "      <td>0.934609</td>\n",
       "      <td>0.862647</td>\n",
       "      <td>0.808477</td>\n",
       "      <td>0.924596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.193900</td>\n",
       "      <td>0.184624</td>\n",
       "      <td>0.933413</td>\n",
       "      <td>0.861640</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.933573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.182420</td>\n",
       "      <td>0.935407</td>\n",
       "      <td>0.865225</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.933573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>0.180426</td>\n",
       "      <td>0.935008</td>\n",
       "      <td>0.864730</td>\n",
       "      <td>0.804012</td>\n",
       "      <td>0.935368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>0.179980</td>\n",
       "      <td>0.934609</td>\n",
       "      <td>0.864013</td>\n",
       "      <td>0.802773</td>\n",
       "      <td>0.935368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.180068</td>\n",
       "      <td>0.935008</td>\n",
       "      <td>0.864730</td>\n",
       "      <td>0.804012</td>\n",
       "      <td>0.935368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.180183</td>\n",
       "      <td>0.935008</td>\n",
       "      <td>0.864730</td>\n",
       "      <td>0.804012</td>\n",
       "      <td>0.935368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f83358f1ec447b8b938ee24c73fb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1610732a544506a9662b96c50bb6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e31bccad5d7426da9b56b4bb6d1d90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6270' max='6270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6270/6270 04:57, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.385900</td>\n",
       "      <td>0.234158</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.801034</td>\n",
       "      <td>0.761047</td>\n",
       "      <td>0.845455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.239500</td>\n",
       "      <td>0.211402</td>\n",
       "      <td>0.920255</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.781350</td>\n",
       "      <td>0.883636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.213200</td>\n",
       "      <td>0.202619</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.837050</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.887273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.198100</td>\n",
       "      <td>0.199678</td>\n",
       "      <td>0.926635</td>\n",
       "      <td>0.841924</td>\n",
       "      <td>0.798046</td>\n",
       "      <td>0.890909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.192200</td>\n",
       "      <td>0.193613</td>\n",
       "      <td>0.927033</td>\n",
       "      <td>0.845570</td>\n",
       "      <td>0.788976</td>\n",
       "      <td>0.910909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>0.192572</td>\n",
       "      <td>0.929426</td>\n",
       "      <td>0.850380</td>\n",
       "      <td>0.794629</td>\n",
       "      <td>0.914545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.190747</td>\n",
       "      <td>0.929426</td>\n",
       "      <td>0.850633</td>\n",
       "      <td>0.793701</td>\n",
       "      <td>0.916364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.188900</td>\n",
       "      <td>0.188840</td>\n",
       "      <td>0.927432</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.916364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>0.189435</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.794953</td>\n",
       "      <td>0.916364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>0.189231</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.794953</td>\n",
       "      <td>0.916364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    fp16 = True)\n",
    "\n",
    "all_test_metrics = []\n",
    "\n",
    "for seed in range(5):\n",
    "    cv_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id).to(device)\n",
    "    \n",
    "\n",
    "    ##### Split the data #####\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "    train_testvalid = dataset.train_test_split(0.2, seed=seed)\n",
    "    # Split the 10% test + valid in half test, half valid\n",
    "    test_valid = train_testvalid['test'].train_test_split(0.5)\n",
    "    # gather everyone if you want to have a single DatasetDict\n",
    "    train_test_valid_dataset = DatasetDict({\n",
    "        'train': train_testvalid['train'],\n",
    "        'test': test_valid['test'],\n",
    "        'valid': test_valid['train']})\n",
    "\n",
    "    dataset = train_test_valid_dataset\n",
    "    tokenized_text = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=cv_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_text[\"train\"],\n",
    "        eval_dataset=tokenized_text[\"valid\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    #Evaluate on test set\n",
    "    predictions = trainer.predict(tokenized_text[\"test\"])\n",
    "    all_test_metrics.append(predictions.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_loss</th>\n",
       "      <td>0.183553</td>\n",
       "      <td>0.013981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.931499</td>\n",
       "      <td>0.004755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.856752</td>\n",
       "      <td>0.008005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.793588</td>\n",
       "      <td>0.007768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.930851</td>\n",
       "      <td>0.008842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_runtime</th>\n",
       "      <td>0.911480</td>\n",
       "      <td>0.004860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_samples_per_second</th>\n",
       "      <td>2751.633200</td>\n",
       "      <td>14.688787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_steps_per_second</th>\n",
       "      <td>172.251200</td>\n",
       "      <td>0.919690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean        std\n",
       "test_loss                   0.183553   0.013981\n",
       "test_accuracy               0.931499   0.004755\n",
       "test_f1                     0.856752   0.008005\n",
       "test_precision              0.793588   0.007768\n",
       "test_recall                 0.930851   0.008842\n",
       "test_runtime                0.911480   0.004860\n",
       "test_samples_per_second  2751.633200  14.688787\n",
       "test_steps_per_second     172.251200   0.919690"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_table = pd.DataFrame(all_test_metrics)\n",
    "\n",
    "full_res = pd.concat([res_table.mean(), res_table.std()], axis=1)\n",
    "full_res.columns = ['mean', 'std']\n",
    "full_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT (with LoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    fp16 = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874d1196003f46569a29cd353a37122d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59908b0a5f5c4b08b1e341f89faf2d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5a5bbeed144953a9f283e57fc7fb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3763' max='6270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3763/6270 08:19 < 05:33, 7.53 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.226400</td>\n",
       "      <td>0.183298</td>\n",
       "      <td>0.929426</td>\n",
       "      <td>0.854560</td>\n",
       "      <td>0.781955</td>\n",
       "      <td>0.942029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.198609</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.848967</td>\n",
       "      <td>0.756374</td>\n",
       "      <td>0.967391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.172700</td>\n",
       "      <td>0.183502</td>\n",
       "      <td>0.931021</td>\n",
       "      <td>0.858313</td>\n",
       "      <td>0.783259</td>\n",
       "      <td>0.949275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.150700</td>\n",
       "      <td>0.191341</td>\n",
       "      <td>0.926635</td>\n",
       "      <td>0.843003</td>\n",
       "      <td>0.796774</td>\n",
       "      <td>0.894928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.129800</td>\n",
       "      <td>0.180579</td>\n",
       "      <td>0.933014</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.794479</td>\n",
       "      <td>0.938406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.193539</td>\n",
       "      <td>0.931021</td>\n",
       "      <td>0.847845</td>\n",
       "      <td>0.823932</td>\n",
       "      <td>0.873188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google-bert/bert-base-multilingual-cased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n",
    "\n",
    "def preprocess_function(examples, batched = True):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "train_testvalid = dataset.train_test_split(0.2, seed=42)\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(0.5)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']})\n",
    "\n",
    "dataset = train_test_valid_dataset\n",
    "tokenized_text = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bert\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    fp16 = True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_text[\"train\"],\n",
    "    eval_dataset=tokenized_text[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
