{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return clf_metrics.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CamemBERT\n",
    "- DistillBERT version fr (https://huggingface.co/cmarkea/distilcamembert-base)\n",
    "    - Comparer avec distillbert de base\n",
    "- LoRA avec Bert ou CamemBERT, faire varier le rang\n",
    "- Baseline avec sklearn\n",
    "\n",
    "\n",
    "- Prendre les milleures préd et compiler quelqes stats dessus (notamment les erreurs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Breton Cyrille menuisier 25 Garçon française</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferazzi Auguste vitrier 30 Garçon Piémontaise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machol Pierre vitrier 24 Garçon Piémontaise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desbois Alexandre prop re 48 Homme marié franç...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vignat Zélie prop re sa fe 30 française</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>Chameton-Dideron Marie chef 1869 idem Pailharès</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25076</th>\n",
       "      <td>Ode Marie ouv chaus res chef Cara 1863 idem St...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25077</th>\n",
       "      <td>Berni Nello manoeuvre chef Baretto 1886 italie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25078</th>\n",
       "      <td>Berni-Laureti Annunziata épouse 1887 idem idem</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25079</th>\n",
       "      <td>Berni Primo fils 1914 idem idem</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25080 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0           Breton Cyrille menuisier 25 Garçon française      0\n",
       "1          Ferazzi Auguste vitrier 30 Garçon Piémontaise      1\n",
       "2            Machol Pierre vitrier 24 Garçon Piémontaise      1\n",
       "3      Desbois Alexandre prop re 48 Homme marié franç...      1\n",
       "4                Vignat Zélie prop re sa fe 30 française      0\n",
       "...                                                  ...    ...\n",
       "25075    Chameton-Dideron Marie chef 1869 idem Pailharès      1\n",
       "25076  Ode Marie ouv chaus res chef Cara 1863 idem St...      1\n",
       "25077  Berni Nello manoeuvre chef Baretto 1886 italie...      1\n",
       "25078     Berni-Laureti Annunziata épouse 1887 idem idem      0\n",
       "25079                    Berni Primo fils 1914 idem idem      0\n",
       "\n",
       "[25080 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('entities.csv', sep=',')\n",
    "df.rename(columns={'chef':'label', 'texte':'text'}, inplace=True)\n",
    "df.label = df.label.astype('int')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "def preprocess_function(examples, batched = True):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578ce97e2e47458d9a91012b4b7a55dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b1bcffdab1425aa2953ff5f1d299bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3c7746010047e7838d373f3a2266fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4013 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "train_testvalid = dataset.train_test_split(0.2, seed=42)\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "train_valid = train_testvalid['train'].train_test_split(0.2, seed=42)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': train_valid['train'],\n",
    "    'test': train_testvalid['test'],\n",
    "    'valid': train_valid['test']})\n",
    "\n",
    "\n",
    "dataset = train_test_valid_dataset\n",
    "tokenized_text = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding = 'longest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2510' max='2510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2510/2510 02:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.261800</td>\n",
       "      <td>0.184132</td>\n",
       "      <td>0.932220</td>\n",
       "      <td>0.853921</td>\n",
       "      <td>0.795796</td>\n",
       "      <td>0.921205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>0.179823</td>\n",
       "      <td>0.930725</td>\n",
       "      <td>0.853530</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.938586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.186108</td>\n",
       "      <td>0.933466</td>\n",
       "      <td>0.856683</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.924681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.182690</td>\n",
       "      <td>0.935958</td>\n",
       "      <td>0.860553</td>\n",
       "      <td>0.809184</td>\n",
       "      <td>0.918888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.183073</td>\n",
       "      <td>0.934961</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>0.801000</td>\n",
       "      <td>0.928158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2510, training_loss=0.1949544667247757, metrics={'train_runtime': 159.5191, 'train_samples_per_second': 503.106, 'train_steps_per_second': 15.735, 'total_flos': 478475089924740.0, 'train_loss': 0.1949544667247757, 'epoch': 5.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert\",\n",
    "    learning_rate=6e-6,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.05,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    fp16 = True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_text[\"train\"],\n",
    "    eval_dataset=tokenized_text[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/314 00:00 < 00:02, 155.62 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06957735247208932\n"
     ]
    }
   ],
   "source": [
    "#Evaluate on test set \n",
    "predictions = trainer.predict(tokenized_text[\"test\"])\n",
    "print(np.mean(predictions.predictions.argmax(axis=1) != predictions.label_ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3611,  295],\n",
       "       [  54, 1056]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions.label_ids, predictions.predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98851fc8245641dca58acd92f7f51426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19060 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0f267d11c34d65a7a24eea02b78f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03e3ded5ff94cfc87199edc3f6cd015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2384' max='2384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2384/2384 01:50, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.180369</td>\n",
       "      <td>0.940239</td>\n",
       "      <td>0.881423</td>\n",
       "      <td>0.832090</td>\n",
       "      <td>0.936975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.167976</td>\n",
       "      <td>0.943227</td>\n",
       "      <td>0.887574</td>\n",
       "      <td>0.836431</td>\n",
       "      <td>0.945378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.160885</td>\n",
       "      <td>0.942231</td>\n",
       "      <td>0.887597</td>\n",
       "      <td>0.823741</td>\n",
       "      <td>0.962185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.168900</td>\n",
       "      <td>0.162238</td>\n",
       "      <td>0.945219</td>\n",
       "      <td>0.891945</td>\n",
       "      <td>0.837638</td>\n",
       "      <td>0.953782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD  0\n",
      "{'test_loss': 0.19174401462078094, 'test_accuracy': 0.9284290271132376, 'test_f1': 0.8540056933712892, 'test_precision': 0.7888805409466566, 'test_recall': 0.9308510638297872, 'test_runtime': 1.7646, 'test_samples_per_second': 2842.637, 'test_steps_per_second': 177.948}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e2b2d6a4ad44acaf13f03275e570f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19060 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a9c7516f1147e6bf0d49fff5ef48ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09907e8853b446b0b7616b9ccab3d47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2384' max='2384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2384/2384 01:50, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.246500</td>\n",
       "      <td>0.186793</td>\n",
       "      <td>0.931275</td>\n",
       "      <td>0.863905</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>0.948052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.183038</td>\n",
       "      <td>0.933267</td>\n",
       "      <td>0.867327</td>\n",
       "      <td>0.799270</td>\n",
       "      <td>0.948052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.175400</td>\n",
       "      <td>0.179777</td>\n",
       "      <td>0.929283</td>\n",
       "      <td>0.860511</td>\n",
       "      <td>0.787770</td>\n",
       "      <td>0.948052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.178519</td>\n",
       "      <td>0.932271</td>\n",
       "      <td>0.866142</td>\n",
       "      <td>0.794224</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD  1\n",
      "{'test_loss': 0.19034463167190552, 'test_accuracy': 0.9344098883572568, 'test_f1': 0.8633153302866639, 'test_precision': 0.8123534010946052, 'test_recall': 0.9210992907801419, 'test_runtime': 1.787, 'test_samples_per_second': 2807.0, 'test_steps_per_second': 175.717}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582841a581934b1a934afd839ad0e10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19060 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e526c7c1014ae0b38292b9e09025ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1131fc6e9949ad8b937d4a66cb0ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2384' max='2384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2384/2384 01:50, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.249100</td>\n",
       "      <td>0.202319</td>\n",
       "      <td>0.930279</td>\n",
       "      <td>0.857724</td>\n",
       "      <td>0.790262</td>\n",
       "      <td>0.937778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.194275</td>\n",
       "      <td>0.931275</td>\n",
       "      <td>0.861167</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.951111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.192630</td>\n",
       "      <td>0.932271</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.798479</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.168700</td>\n",
       "      <td>0.192298</td>\n",
       "      <td>0.933267</td>\n",
       "      <td>0.862986</td>\n",
       "      <td>0.799242</td>\n",
       "      <td>0.937778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD  2\n",
      "{'test_loss': 0.18135252594947815, 'test_accuracy': 0.9302232854864434, 'test_f1': 0.8579545454545454, 'test_precision': 0.7911676646706587, 'test_recall': 0.9370567375886525, 'test_runtime': 1.7767, 'test_samples_per_second': 2823.189, 'test_steps_per_second': 176.731}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64374c45c3840fe99ac8e836f3cf7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19060 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af63e5cee5e4dd79141d829d879b462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716422f0f28149ceb48e1a55db426514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2384' max='2384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2384/2384 01:51, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.177844</td>\n",
       "      <td>0.938247</td>\n",
       "      <td>0.869198</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.907489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.167225</td>\n",
       "      <td>0.940239</td>\n",
       "      <td>0.877049</td>\n",
       "      <td>0.819923</td>\n",
       "      <td>0.942731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.176300</td>\n",
       "      <td>0.168645</td>\n",
       "      <td>0.938247</td>\n",
       "      <td>0.873984</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.947137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>0.167532</td>\n",
       "      <td>0.942231</td>\n",
       "      <td>0.881148</td>\n",
       "      <td>0.823755</td>\n",
       "      <td>0.947137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD  3\n",
      "{'test_loss': 0.1807997226715088, 'test_accuracy': 0.9322169059011164, 'test_f1': 0.862570735650768, 'test_precision': 0.7927191679049034, 'test_recall': 0.9459219858156028, 'test_runtime': 1.7811, 'test_samples_per_second': 2816.182, 'test_steps_per_second': 176.292}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66358c06f6fc476c81717f8fd5698c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19060 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df07ee684bc4c50a3d4535befe86cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edb6f5c77b443b884f6f9f5b8dedcc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2384' max='2384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2384/2384 01:51, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.250500</td>\n",
       "      <td>0.179783</td>\n",
       "      <td>0.936255</td>\n",
       "      <td>0.867769</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.173620</td>\n",
       "      <td>0.941235</td>\n",
       "      <td>0.877847</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.170909</td>\n",
       "      <td>0.943227</td>\n",
       "      <td>0.881988</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.934211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.170400</td>\n",
       "      <td>0.170942</td>\n",
       "      <td>0.941235</td>\n",
       "      <td>0.878351</td>\n",
       "      <td>0.828794</td>\n",
       "      <td>0.934211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD  4\n",
      "{'test_loss': 0.1854034811258316, 'test_accuracy': 0.9316188197767146, 'test_f1': 0.8586732591676968, 'test_precision': 0.8021555042340262, 'test_recall': 0.9237588652482269, 'test_runtime': 1.8042, 'test_samples_per_second': 2780.229, 'test_steps_per_second': 174.041}\n"
     ]
    }
   ],
   "source": [
    "str = \"distilbert/distilbert-base-uncased\"\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(str)\n",
    "\n",
    "\n",
    "def preprocess_function(examples, batched = True):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert\",\n",
    "    learning_rate=6e-6,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.05,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    fp16 = True)\n",
    "\n",
    "all_test_metrics = []\n",
    "\n",
    "df = pd.read_csv('entities.csv', sep=',')\n",
    "df.rename(columns={'chef':'label', 'texte':'text'}, inplace=True)\n",
    "df.label = df.label.astype('int')\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(df.text, df.label)):\n",
    "    dataset_train = dataset.select(train_index)\n",
    "    dataset_test = dataset.select(test_index)\n",
    "    dataset_train_val = dataset_train.train_test_split(0.05, seed=42)\n",
    "    split_dataset = DatasetDict({\n",
    "        'train': dataset_train_val['train'],\n",
    "        'valid': dataset_train_val['test'],\n",
    "        'test': dataset_test\n",
    "    })\n",
    "\n",
    "    cv_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    str, num_labels=2, id2label=id2label, label2id=label2id).to(device)\n",
    "    \n",
    "    tokenized_text = split_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=cv_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_text[\"train\"],\n",
    "        eval_dataset=tokenized_text[\"valid\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    #Evaluate on test set\n",
    "    predictions = trainer.predict(tokenized_text[\"test\"])\n",
    "    print(\"FOLD \", i)\n",
    "    print(predictions.metrics)\n",
    "    all_test_metrics.append(predictions.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_loss</th>\n",
       "      <td>0.185929</td>\n",
       "      <td>0.005021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.931380</td>\n",
       "      <td>0.002235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.859304</td>\n",
       "      <td>0.003777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.797455</td>\n",
       "      <td>0.009741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.931738</td>\n",
       "      <td>0.010088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_runtime</th>\n",
       "      <td>1.782720</td>\n",
       "      <td>0.014551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_samples_per_second</th>\n",
       "      <td>2813.847400</td>\n",
       "      <td>22.905461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_steps_per_second</th>\n",
       "      <td>176.145800</td>\n",
       "      <td>1.434034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean        std\n",
       "test_loss                   0.185929   0.005021\n",
       "test_accuracy               0.931380   0.002235\n",
       "test_f1                     0.859304   0.003777\n",
       "test_precision              0.797455   0.009741\n",
       "test_recall                 0.931738   0.010088\n",
       "test_runtime                1.782720   0.014551\n",
       "test_samples_per_second  2813.847400  22.905461\n",
       "test_steps_per_second     176.145800   1.434034"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_table = pd.DataFrame(all_test_metrics)\n",
    "\n",
    "full_res = pd.concat([res_table.mean(), res_table.std()], axis=1)\n",
    "full_res.columns = ['mean', 'std']\n",
    "full_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilCamemBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 16051\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 5016\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 4013\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d64a89251374ce98583ddde486a344b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cdeb31c2094808aa9a9344c296c92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd684ffa4ef479987f762199505a081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4013 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2008' max='2008' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2008/2008 02:09, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.177436</td>\n",
       "      <td>0.930725</td>\n",
       "      <td>0.851337</td>\n",
       "      <td>0.790467</td>\n",
       "      <td>0.922364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.176616</td>\n",
       "      <td>0.931473</td>\n",
       "      <td>0.854574</td>\n",
       "      <td>0.785992</td>\n",
       "      <td>0.936269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.173453</td>\n",
       "      <td>0.933466</td>\n",
       "      <td>0.857296</td>\n",
       "      <td>0.795635</td>\n",
       "      <td>0.929316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.172576</td>\n",
       "      <td>0.934712</td>\n",
       "      <td>0.860341</td>\n",
       "      <td>0.796644</td>\n",
       "      <td>0.935110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2008, training_loss=0.19646803334177254, metrics={'train_runtime': 129.6097, 'train_samples_per_second': 495.364, 'train_steps_per_second': 15.493, 'total_flos': 341023605394308.0, 'train_loss': 0.19646803334177254, 'epoch': 4.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = \"cmarkea/distilcamembert-base\"\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(str)\n",
    "\n",
    "\n",
    "def preprocess_function(examples, batched = True):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "train_testvalid = dataset.train_test_split(0.2, seed=42)\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "train_valid = train_testvalid['train'].train_test_split(0.2, seed=42)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': train_valid['train'],\n",
    "    'test': train_testvalid['test'],\n",
    "    'valid': train_valid['test']})\n",
    "\n",
    "\n",
    "dataset = train_test_valid_dataset\n",
    "print(dataset)\n",
    "tokenized_text = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    str, num_labels=2, id2label=id2label, label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilCAMEMbert\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    fp16 = True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_text[\"train\"],\n",
    "    eval_dataset=tokenized_text[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  5/314 00:00 < 00:01, 159.70 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06778309409888357\n"
     ]
    }
   ],
   "source": [
    "#Evaluate on test set \n",
    "predictions = trainer.predict(tokenized_text[\"test\"])\n",
    "print(np.mean(predictions.predictions.argmax(axis=1) != predictions.label_ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.9848633,  1.0458984],\n",
       "       [ 3.0234375, -3.375    ],\n",
       "       [-1.1279297,  1.2763672],\n",
       "       ...,\n",
       "       [ 2.984375 , -3.3515625],\n",
       "       [ 2.9316406, -3.3574219],\n",
       "       [ 2.6601562, -2.9082031]], dtype=float32), label_ids=array([1, 0, 0, ..., 0, 0, 0]), metrics={'test_loss': 0.17468680441379547, 'test_accuracy': 0.9322169059011164, 'test_f1': 0.8614506927465363, 'test_precision': 0.7864583333333334, 'test_recall': 0.9522522522522523, 'test_runtime': 1.7809, 'test_samples_per_second': 2816.554, 'test_steps_per_second': 176.315})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f14b146a8e84896bd14aa36bf47720e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19863 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c507bb8d4314263849397481fedc739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8700d5d97834c8b9ed5d14133bc25c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3105' max='3105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3105/3105 02:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>0.159148</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.159403</td>\n",
       "      <td>0.945274</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.166142</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.177200</td>\n",
       "      <td>0.172803</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.165200</td>\n",
       "      <td>0.165153</td>\n",
       "      <td>0.945274</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD  0\n",
      "{'test_loss': 0.18460464477539062, 'test_accuracy': 0.9288277511961722, 'test_f1': 0.8548190321268808, 'test_precision': 0.7896318557475582, 'test_recall': 0.9317375886524822, 'test_runtime': 1.7547, 'test_samples_per_second': 2858.648, 'test_steps_per_second': 178.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e168689421479d919243131c2041cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19863 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1bf0161da8452ab3ec7f42717e5aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d748bed46cd45e6b373003866215d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3105' max='3105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3105/3105 02:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.182556</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.171490</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.171524</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.166233</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.166313</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD  1\n",
      "{'test_loss': 0.18357910215854645, 'test_accuracy': 0.9350079744816587, 'test_f1': 0.8663934426229508, 'test_precision': 0.805640243902439, 'test_recall': 0.9370567375886525, 'test_runtime': 1.7855, 'test_samples_per_second': 2809.345, 'test_steps_per_second': 175.864}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876abb754922453d829e9a29a9429145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19863 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b91ac880a254bf89462243fc3ecb3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f65e477bb84e9486a88b7c4377ef06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3105' max='3105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3105/3105 02:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.258300</td>\n",
       "      <td>0.156931</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.938776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.189400</td>\n",
       "      <td>0.138456</td>\n",
       "      <td>0.950249</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.959184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.137356</td>\n",
       "      <td>0.950249</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.959184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.134795</td>\n",
       "      <td>0.950249</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.959184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.159300</td>\n",
       "      <td>0.136748</td>\n",
       "      <td>0.950249</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.959184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD  2\n",
      "{'test_loss': 0.18177413940429688, 'test_accuracy': 0.930622009569378, 'test_f1': 0.8592233009708737, 'test_precision': 0.7901785714285714, 'test_recall': 0.9414893617021277, 'test_runtime': 1.8505, 'test_samples_per_second': 2710.63, 'test_steps_per_second': 169.685}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0466bcd5347445e3821170b02358c87d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19863 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b7cf3aaf014330890bec55c0473724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd8ffe8049f4808a05e26841efd3685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3105' max='3105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3105/3105 02:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.179219</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.891304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.192900</td>\n",
       "      <td>0.159892</td>\n",
       "      <td>0.945274</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.144239</td>\n",
       "      <td>0.950249</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.133372</td>\n",
       "      <td>0.955224</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.164900</td>\n",
       "      <td>0.132404</td>\n",
       "      <td>0.955224</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD  3\n",
      "{'test_loss': 0.1750919222831726, 'test_accuracy': 0.9346092503987241, 'test_f1': 0.8674211802748585, 'test_precision': 0.7971768202080238, 'test_recall': 0.9512411347517731, 'test_runtime': 1.7541, 'test_samples_per_second': 2859.52, 'test_steps_per_second': 179.005}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df3d0c837f74870be41bc647b2ca77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19863 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a03365517c14031a664d00a6b563d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a77668fbab46469190c96203cf35fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/meilame.tayebjee/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3105' max='3105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3105/3105 02:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.259800</td>\n",
       "      <td>0.160656</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.154001</td>\n",
       "      <td>0.945274</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.172600</td>\n",
       "      <td>0.152318</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.151265</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.148314</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD  4\n",
      "{'test_loss': 0.18896128237247467, 'test_accuracy': 0.9302232854864434, 'test_f1': 0.8562037797863599, 'test_precision': 0.7978560490045942, 'test_recall': 0.9237588652482269, 'test_runtime': 1.7683, 'test_samples_per_second': 2836.698, 'test_steps_per_second': 177.576}\n"
     ]
    }
   ],
   "source": [
    "str = \"cmarkea/distilcamembert-base\"\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(str)\n",
    "\n",
    "\n",
    "def preprocess_function(examples, batched = True):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert\",\n",
    "    learning_rate=8e-6,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.05,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    fp16 = True)\n",
    "\n",
    "all_test_metrics = []\n",
    "\n",
    "df = pd.read_csv('entities.csv', sep=',')\n",
    "df.rename(columns={'chef':'label', 'texte':'text'}, inplace=True)\n",
    "df.label = df.label.astype('int')\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(df.text, df.label)):\n",
    "    dataset_train = dataset.select(train_index)\n",
    "    dataset_test = dataset.select(test_index)\n",
    "    dataset_train_val = dataset_train.train_test_split(0.01, seed=42)\n",
    "    split_dataset = DatasetDict({\n",
    "        'train': dataset_train_val['train'],\n",
    "        'valid': dataset_train_val['test'],\n",
    "        'test': dataset_test\n",
    "    })\n",
    "\n",
    "    cv_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    str, num_labels=2, id2label=id2label, label2id=label2id).to(device)\n",
    "    \n",
    "    tokenized_text = split_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=cv_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_text[\"train\"],\n",
    "        eval_dataset=tokenized_text[\"valid\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    #Evaluate on test set\n",
    "    predictions = trainer.predict(tokenized_text[\"test\"])\n",
    "    print(\"FOLD \", i)\n",
    "    print(predictions.metrics)\n",
    "    all_test_metrics.append(predictions.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_loss</th>\n",
       "      <td>0.182802</td>\n",
       "      <td>0.005057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.931858</td>\n",
       "      <td>0.002778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.860812</td>\n",
       "      <td>0.005799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.796097</td>\n",
       "      <td>0.006560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.937057</td>\n",
       "      <td>0.010320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_runtime</th>\n",
       "      <td>1.782620</td>\n",
       "      <td>0.040044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_samples_per_second</th>\n",
       "      <td>2814.968200</td>\n",
       "      <td>61.812322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_steps_per_second</th>\n",
       "      <td>176.216000</td>\n",
       "      <td>3.869132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean        std\n",
       "test_loss                   0.182802   0.005057\n",
       "test_accuracy               0.931858   0.002778\n",
       "test_f1                     0.860812   0.005799\n",
       "test_precision              0.796097   0.006560\n",
       "test_recall                 0.937057   0.010320\n",
       "test_runtime                1.782620   0.040044\n",
       "test_samples_per_second  2814.968200  61.812322\n",
       "test_steps_per_second     176.216000   3.869132"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_table = pd.DataFrame(all_test_metrics)\n",
    "\n",
    "full_res = pd.concat([res_table.mean(), res_table.std()], axis=1)\n",
    "full_res.columns = ['mean', 'std']\n",
    "full_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CamemBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    fp16 = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110623490"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"camembert-base\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "sum([param.nelement() for param in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoModelForSequenceClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamembert-base\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, id2label\u001b[38;5;241m=\u001b[39mid2label, label2id\u001b[38;5;241m=\u001b[39mlabel2id\n\u001b[1;32m      3\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamembert-base\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_function\u001b[39m(examples, batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoModelForSequenceClassification' is not defined"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"camembert-base'\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"camembert-base'\")\n",
    "\n",
    "def preprocess_function(examples, batched = True):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "train_testvalid = dataset.train_test_split(0.2, seed=42)\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(0.5)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']})\n",
    "\n",
    "dataset = train_test_valid_dataset\n",
    "tokenized_text = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"camembert\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    fp16 = True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_text[\"train\"],\n",
    "    eval_dataset=tokenized_text[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
